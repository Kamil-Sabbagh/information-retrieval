{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7c30px5HbrW"
      },
      "source": [
        "# Building inverted index and answering queries\n",
        "\n",
        "In the first part of the lab you are going to implement a standard document processing pipeline and then build a simple search engine based on it:\n",
        "- starting from crawling documents,\n",
        "- then building an inverted index,\n",
        "- and answering queries using this index.\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "First, we need a unified approach to documents and queries preprocessing. Implement a class responsible for that. Complete the code for given functions (most of them are just one-liners) and make sure you pass the tests. Make use of `nltk` library, `spacy`, or any other you know."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "den9w0x-d61x",
        "outputId": "1595d145-a5ad-4ee9-cdd7-22a32d19c530"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o2kGKev8HbrX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "class Preprocessor:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stop_words = {'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
        "                      'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with'}\n",
        "        self.ps = nltk.stem.PorterStemmer()\n",
        "\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        #TODO word tokenize text using nltk lib\n",
        "\n",
        "        return ['one', 'two', 'three']\n",
        "\n",
        "\n",
        "    def stem(self, word, stemmer):\n",
        "\n",
        "        #TODO stem word using provided stemmer\n",
        "\n",
        "        return 'stemmed_word'\n",
        "\n",
        "\n",
        "    def is_apt_word(self, word):\n",
        "        #TODO check if word is appropriate - not a stop word and isalpha,\n",
        "        # i.e consists of letters, not punctuation, numbers, dates\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        # and stem it, ignoring not appropriate words\n",
        "\n",
        "\n",
        "        return ['one', 'two', 'three']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lNkN9IfHbrY"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZbcaEo8ZHbrY"
      },
      "outputs": [],
      "source": [
        "prep = Preprocessor()\n",
        "text = 'To be, or not to be, that is the question'\n",
        "\n",
        "assert prep.tokenize(text) == ['To', 'be', ',', 'or', 'not', 'to', 'be', ',', 'that', 'is', 'the', 'question']\n",
        "assert prep.stem('retrieval', prep.ps) == 'retriev'\n",
        "assert prep.is_apt_word('qwerty123') is False\n",
        "assert prep.preprocess(text) == ['or', 'not', 'question']"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UnNItHIQWKKJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA8EoPQcHbrY"
      },
      "source": [
        "## Crawling and Indexing\n",
        "\n",
        "### Base classes\n",
        "\n",
        "Here are some base classes you will need for writing an indexer. The code is given, still, you need to change some. Namely, the `parse` method (it is also possible to use your own implementations of other methods, just make sure they work). The reason to change is that the method always makes complete parsing, which we want to avoid, when we only need e.g. links or a specific portions of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2ORTuCvAHbrY"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "import urllib.parse\n",
        "import os\n",
        "\n",
        "\n",
        "class Document:\n",
        "\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "\n",
        "    def download(self):\n",
        "        try:\n",
        "            response = requests.get(self.url)\n",
        "            if response.status_code == 200:\n",
        "                self.content = response.content\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def persist(self, path):\n",
        "        # this code is not supposed to be good :)\n",
        "        # Please discuss why this line is bad\n",
        "        with open(os.path.join(path, quote(self.url).replace('/', '_')), 'wb') as f:\n",
        "            f.write(self.content)\n",
        "\n",
        "\n",
        "class HtmlnbcnewsArticle(Document):\n",
        "\n",
        "    def normalize(self, href):\n",
        "        if href is not None and href[:4] != 'http':\n",
        "            href = urllib.parse.urljoin(self.url, href)\n",
        "        return href\n",
        "\n",
        "    def parse(self):\n",
        "        #TODO change this method\n",
        "\n",
        "        def tag_visible(element):\n",
        "            if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
        "                return False\n",
        "            if isinstance(element, Comment):\n",
        "                return False\n",
        "            return True\n",
        "\n",
        "        model = BeautifulSoup(self.content, \"html.parser\")\n",
        "\n",
        "        self.anchors = []\n",
        "        a = model.find_all('a')\n",
        "        for anchor in a:\n",
        "            href = self.normalize(anchor.get('href'))\n",
        "            text = anchor.text\n",
        "            self.anchors.append((text, href))\n",
        "\n",
        "        # extract only header and main content\n",
        "        # discuss why using classes like article-body__content__17Yit\n",
        "        # is the wrong strategy\n",
        "        header = ### TODO\n",
        "        content = ### TODO\n",
        "\n",
        "\n",
        "        if header is None or content is None:\n",
        "          self.content = content\n",
        "        if content:\n",
        "            content = content.parent\n",
        "        else:\n",
        "\n",
        "            content = model.find('p')\n",
        "            print(f'article body not found: {content}')\n",
        "\n",
        "        if header is None or content is None:\n",
        "            self.article_text = \"\"\n",
        "            return\n",
        "\n",
        "        texts = header.findAll(string=True) + content.findAll(string=True)\n",
        "        visible_texts = filter(tag_visible, texts)\n",
        "        self.article_text = \"\\n\".join(t.strip() for t in visible_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HnJnucucHbrZ",
        "outputId": "a331f50f-b73a-4305-9db5-1bcffc3521b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jeff Bezos sells nearly 12 million Amazon shares worth at least $2 billion, with more to come\n"
          ]
        }
      ],
      "source": [
        "doc = HtmlnbcnewsArticle(\"https://www.nbcnews.com/news/us-news/jeff-bezos-sells-nearly-12-million-amazon-shares-least-2-billion-come-rcna138274\")\n",
        "doc.download()\n",
        "\n",
        "doc.parse()\n",
        "print(doc.article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjJxYtOqHbrZ"
      },
      "source": [
        "### Main class\n",
        "\n",
        "The main indexer logic is here. We organize it as a crawler generator that adds certain visited pages to inverted index and saves them on disk.\n",
        "\n",
        "- `crawl_generator_for_index` method crawles the given website doing BFS, starting from `source` within given `depth`. Considers only inner pages (starting with https://www.nbcnews.com/...) for visiting. To speed up, do not consider pages with content type other than `html`: `.pdf`, `.mp3`, `.avi`, `.mp4`, `.txt`, ... . If crawler encounters an article page (of a form https://www.nbcnews.com/world/...), it saves its content in a file in `collection_path` folder and populates the inverted index calling `index_doc` method. When done, saves on disk three resulting dictionaries:\n",
        "    - `doc_urls`: `{doc_id : url}`\n",
        "    - `index`: `{term : [collection_frequency, (doc_id_1, doc_freq_1), (doc_id_2, doc_freq_2), ...]}`\n",
        "    - `doc_lengths`: `{doc_id : doc_length}`\n",
        "\n",
        "    `limit` parameter is given for testing - if not `None`, break the loop when number of saved articles exceeds the `limit` and return without writing dictionaries to disk.\n",
        "    \n",
        "- `index_doc` method parses and preprocesses the content of a `doc` and adds it to the inverted index. Also keeps track of document lengths in a `doc_lengths` dictionary.\n",
        "\n",
        "Your crawler have to print visited urls as it runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n9i_kLMlHbrZ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from queue import Queue\n",
        "import pickle\n",
        "import os\n",
        "import re\n",
        "\n",
        "class nbcnewsSpecificIndexer:\n",
        "\n",
        "    def __init__(self):\n",
        "        # dictionaries to populate\n",
        "        self.doc_urls = {}\n",
        "        self.index = {}\n",
        "        self.doc_lengths = {}\n",
        "        # preprocessor\n",
        "        self.prep = Preprocessor()\n",
        "\n",
        "\n",
        "    def crawl_generator_for_index(self, source, depth, collection_path=\"collection\", limit=None):\n",
        "\n",
        "        q = Queue()\n",
        "        q.put((source, 0))\n",
        "        visited = set()\n",
        "        doc_counter = 0\n",
        "        # creating a folder if needed\n",
        "        if not os.path.exists(collection_path):\n",
        "            os.makedirs(collection_path)\n",
        "        # doing a BFS\n",
        "        while not q.empty():\n",
        "            url, url_depth = q.get()\n",
        "            if url not in visited:\n",
        "                visited.add(url)\n",
        "                try:\n",
        "                    doc = HtmlnbcnewsArticle(url)    # download and parse url\n",
        "                    if doc.download():\n",
        "                        doc.parse()\n",
        "                        ### TODO write a regular expression that will match only webpages under nbcnews domain\n",
        "                        if re.match(r'...', url):\n",
        "\n",
        "                        # if url.startswith(\"https://www.nbcnews.com/\"):\n",
        "                            # print(url)\n",
        "                            doc.persist(collection_path)\n",
        "                            self.doc_urls[doc_counter] = url\n",
        "                            self.index_doc(doc, doc_counter)\n",
        "                            doc_counter += 1\n",
        "                            yield doc\n",
        "                            if limit is not None and doc_counter == limit:\n",
        "                                return\n",
        "\n",
        "                            # filter links, consider only inner html pages\n",
        "                        if url_depth + 1 < depth:\n",
        "                            valid_anchors = filter(self.accepted_url, doc.anchors)\n",
        "                            for a in valid_anchors:\n",
        "                                q.put((a[1], url_depth + 1))\n",
        "\n",
        "                except FileNotFoundError as e:\n",
        "                    print(\"Analyzing\", url, \"led to FileNotFoundError\")\n",
        "\n",
        "\n",
        "    def accepted_url(self, anchor):\n",
        "        url = str(anchor[1])\n",
        "        if not url.startswith(\"https://www.nbcnews.com\"):\n",
        "            return False\n",
        "        if url[-4:]  in ('.pdf', '.mp3', '.avi', '.mp4', '.txt'):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "\n",
        "    def index_doc(self, doc, doc_id):\n",
        "        # add documents to index\n",
        "        doc.parse()\n",
        "        # preprocess - tokenize, remove stopwords and non-alphanumeric tokens and stem\n",
        "        content = self.prep.preprocess(doc.article_text)\n",
        "        self.doc_lengths[doc_id] = len(content)\n",
        "        # get dict of terms in current article\n",
        "        article_index = Counter(content)\n",
        "        # update global index\n",
        "        for term in article_index.keys():\n",
        "            article_freq = article_index[term]\n",
        "            if term not in self.index:\n",
        "                self.index[term] = [article_freq, (doc_id, article_freq)]\n",
        "            else:\n",
        "                self.index[term][0] += article_freq\n",
        "                self.index[term].append((doc_id, article_freq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjECDhcmHbrZ"
      },
      "source": [
        "### Tests\n",
        "\n",
        "Please make sure your crawler prints out urls with `print(k, c.url)`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "requests.get('https://www.nbcnews.com/news/us-news/jeff-bezos-sells-nearly-12-million-amazon-shares-least-2-billion-come-rcna138274').status_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJwF8gd0isX2",
        "outputId": "d0b626d7-7295-4d14-c797-7adc43269906"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2FRr1MFvHbrZ",
        "outputId": "cd9c2cd7-6889-47da-8225-31aea08a2394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 https://www.nbcnews.com/politics/2024-election/live-blog/harris-trump-presidential-election-live-updates-rcna171168\n",
            "2 https://www.nbcnews.com/news/us-news/nbc-affiliates-n19981\n",
            "3 https://www.nbcnews.com/news/weather\n",
            "4 https://www.nbcnews.com/politics/2024-presidential-election\n",
            "5 https://www.nbcnews.com/news/nbc-news-now-live-audio-listen-live-news-audio-day-rcna70163\n",
            "6 https://www.nbcnews.com/news/us-news/sean-diddy-combs-arrested-rcna145503\n",
            "7 https://www.nbcnews.com/news/us-news/sean-diddy-combs-files-motion-vacate-100m-default-judgment-sexual-assa-rcna170430\n",
            "8 https://www.nbcnews.com/news/us-news/former-danity-kane-member-sues-sean-combs-alleging-groped-threatened-rcna170617\n",
            "9 https://www.nbcnews.com/news/us-news/diddy-lawsuits-timeline-allegations-what-know-rcna145335\n",
            "10 https://www.nbcnews.com/investigations/secret-service-chief-makes-remarkable-admission-need-paradigm-shift-rcna171390\n",
            "11 https://www.nbcnews.com/politics/donald-trump/congress-mulls-new-secret-service-funding-apparent-attempt-trumps-life-rcna171397\n",
            "12 https://www.nbcnews.com/news/us-news/ryan-routh-trump-assassination-attempt-alleged-what-know-rcna171269\n",
            "13 https://www.nbcnews.com/news/us-news/live-blog/trump-assassination-attempt-live-updates-rcna171241\n",
            "14 https://www.nbcnews.com/news/us-news/ryan-routh-was-camped-12-hours-didnt-trump-line-sight-secret-service-f-rcna171290\n",
            "15 https://www.nbcnews.com/news/us-news/video-shows-suspect-apparent-trump-assassination-attempt-apprehended-rcna171306\n"
          ]
        }
      ],
      "source": [
        "indexer = nbcnewsSpecificIndexer()\n",
        "k = 1\n",
        "\n",
        "for c in indexer.crawl_generator_for_index(\n",
        "        source=\"https://www.nbcnews.com/news\",\n",
        "        depth=2,\n",
        "        collection_path=\"test_collection\",\n",
        "        limit=15):\n",
        "    print(k, c.url)\n",
        "    k += 1\n",
        "\n",
        "\n",
        "# assert type(indexer.index) is dict\n",
        "# assert type(indexer.index['nbcnews']) is list\n",
        "# assert type(indexer.index['nbcnews'][0]) is int\n",
        "# assert type(indexer.index['nbcnews'][1]) is tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHI7wDluHbra"
      },
      "source": [
        "Please test these documents contain a desired stem (or its derivate):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexer.index.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw7WJ448jDZT",
        "outputId": "139a6b08-961c-4cd1-8345-a6f96394f7ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['elect', 'updat', 'trump', 'make', 'virtual', 'appear', 'crypto', 'event', 'harri', 'meet', 'teamster', 'nbc', 'affili', 'weather', 'news', 'now', 'live', 'audio', 'sean', 'comb', 'arrest', 'feder', 'agent', 'new', 'york', 'file', 'motion', 'vacat', 'default', 'judgment', 'sexual', 'assault', 'lawsuit', 'inmat', 'former', 'daniti', 'kane', 'member', 'sue', 'alleg', 'grope', 'threaten', 'her', 'timelin', 'what', 'know', 'secret', 'servic', 'chief', 'remark', 'admiss', 'we', 'need', 'paradigm', 'shift', 'congress', 'mull', 'fund', 'after', 'appar', 'attempt', 'life', 'about', 'ryan', 'routh', 'man', 'charg', 'assassin', 'golf', 'cours', 'suspect', 'second', 'plot', 'camp', 'out', 'hour', 'did', 'have', 'hi', 'line', 'sight', 'when', 'fire', 'him', 'video', 'show', 'be'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yBP5FtJLHbra",
        "outputId": "27074b59-f157-44e1-d53e-f6dc5d5d5091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, (4, 1)]\n",
            "https://www.nbcnews.com/news/nbc-news-now-live-audio-listen-live-news-audio-day-rcna70163\n"
          ]
        }
      ],
      "source": [
        "some_stem = 'live'\n",
        "print(indexer.index[some_stem])\n",
        "for pair in indexer.index[some_stem][1:]:\n",
        "    print(indexer.doc_urls[pair[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ9BkdwLHbra"
      },
      "source": [
        "### 1.2.4. Building an index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fe-vfrzNHbra",
        "outputId": "d561a200-c5d2-4d3c-8818-d9299b3c9c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 https://www.nbcnews.com/politics/2024-election/live-blog/harris-trump-presidential-election-live-updates-rcna171168\n",
            "2 https://www.nbcnews.com/news/us-news/nbc-affiliates-n19981\n",
            "3 https://www.nbcnews.com/news/weather\n",
            "4 https://www.nbcnews.com/politics/2024-presidential-election\n",
            "5 https://www.nbcnews.com/news/nbc-news-now-live-audio-listen-live-news-audio-day-rcna70163\n",
            "6 https://www.nbcnews.com/news/us-news/sean-diddy-combs-arrested-rcna145503\n",
            "7 https://www.nbcnews.com/news/us-news/sean-diddy-combs-files-motion-vacate-100m-default-judgment-sexual-assa-rcna170430\n",
            "8 https://www.nbcnews.com/news/us-news/former-danity-kane-member-sues-sean-combs-alleging-groped-threatened-rcna170617\n",
            "9 https://www.nbcnews.com/news/us-news/diddy-lawsuits-timeline-allegations-what-know-rcna145335\n",
            "10 https://www.nbcnews.com/investigations/secret-service-chief-makes-remarkable-admission-need-paradigm-shift-rcna171390\n",
            "11 https://www.nbcnews.com/politics/donald-trump/congress-mulls-new-secret-service-funding-apparent-attempt-trumps-life-rcna171397\n",
            "12 https://www.nbcnews.com/news/us-news/ryan-routh-trump-assassination-attempt-alleged-what-know-rcna171269\n",
            "13 https://www.nbcnews.com/news/us-news/live-blog/trump-assassination-attempt-live-updates-rcna171241\n",
            "14 https://www.nbcnews.com/news/us-news/ryan-routh-was-camped-12-hours-didnt-trump-line-sight-secret-service-f-rcna171290\n",
            "15 https://www.nbcnews.com/news/us-news/video-shows-suspect-apparent-trump-assassination-attempt-apprehended-rcna171306\n",
            "16 https://www.nbcnews.com/politics/donald-trump/trump-dispenses-unity-blames-democrats-apparent-second-assassination-rcna171218\n",
            "17 https://www.nbcnews.com/tech/elon-musk-deletes-x-post-about-assassination-biden-harris-rcna171260\n",
            "18 https://www.nbcnews.com/news/us-news/university-north-texas-corpses-dissected-unclaimed-bodies-rcna170478\n",
            "19 https://www.nbcnews.com/news/us-news/university-north-texas-unclaimed-bodies-investigation-takeaways-rcna171195\n",
            "20 https://www.nbcnews.com/news/us-news/namus-database-coroner-medical-examiner-pauper-cemetery-rarely-used-rcna129741\n",
            "21 https://www.nbcnews.com/specials/nbc-lost-rites-2023/index.html\n",
            "22 https://www.nbcnews.com/news/sports/live-blog/eagles-falcons-nfl-game-live-updates-rcna171235\n",
            "23 https://www.nbcnews.com/news/sports/chiefs-rb-isiah-pacheco-miss-least-6-weeks-surgery-rcna171363\n",
            "24 https://www.nbcnews.com/news/sports/panthers-bench-bryce-young-rcna171334\n",
            "25 https://www.nbcnews.com/news/us-news/miami-heat-decry-threats-hateful-speech-aimed-haitian-immigrants-rcna171332\n",
            "26 https://www.nbcnews.com/news/sports/jordan-chiles-appeals-swiss-supreme-court-reclaim-olympic-bronze-medal-rcna171388\n",
            "27 https://www.nbcnews.com/news/us-news/meta-bans-rt-russian-disinformation-rcna171402\n",
            "28 https://www.nbcnews.com/investigations/rt-russian-state-media-waging-covert-info-war-biden-admin-says-rcna171081\n",
            "29 https://www.nbcnews.com/business/business-news/amazon-workers-must-return-office-full-time-ceo-says-rcna171356\n",
            "30 https://www.nbcnews.com/news/us-news/unnamed-storm-brings-1-foot-rain-parts-north-carolina-heads-north-rcna171398\n",
            "31 https://www.nbcnews.com/news/us-news/houston-area-pipeline-fire-prompts-evacuations-shelter-place-orders-rcna171382\n",
            "32 https://www.nbcnews.com/news/ballerina-michaela-mabinty-deprince-29-mom-died-24-hours-rcna171413\n",
            "33 https://www.nbcnews.com/news/latino/uvalde-families-officers-charged-school-shooting-delayed-justice-rcna171295\n",
            "34 https://www.nbcnews.com/news/us-news/30-bomb-threats-made-springfield-ohio-false-pets-claims-rcna171392\n",
            "35 https://www.nbcnews.com/politics/justice-department/two-former-new-york-city-fire-department-chiefs-indicted-bribery-charg-rcna171285\n",
            "36 https://www.nbcnews.com/politics/2024-election/donald-trump-misrepresents-repeal-affordable-care-act-obamacare-rcna171293\n",
            "37 https://www.nbcnews.com/politics/2024-election/trump-allied-group-launches-spanish-language-ads-warning-noncitizens-v-rcna171378\n",
            "38 https://www.nbcnews.com/politics/politics-news/judge-denies-mark-meadows-effort-move-arizona-case-federal-court-rcna171403\n",
            "39 https://www.nbcnews.com/politics/2024-election/ohio-sheriff-suggests-residents-keep-list-harris-yard-sign-addresses-rcna171385\n",
            "40 https://www.nbcnews.com/politics/congress/house-republicans-struggle-avoid-government-shutdown-trump-rcna170816\n",
            "41 https://www.nbcnews.com/news/us-news/magnitude-51-earthquake-strikes-midland-texas-rcna171408\n",
            "42 https://www.nbcnews.com/tech/crypto/trump-crypto-event-world-liberty-financial-rcna171407\n",
            "43 https://www.nbcnews.com/news/latino/brazilian-mayoral-candidate-hits-opponent-chair-live-debate-rcna171396\n",
            "44 https://www.nbcnews.com/news/latino/dreamers-blast-nicky-jam-endorsing-trump-sought-end-daca-president-rcna171307\n",
            "45 https://www.nbcnews.com/select/shopping/target-circle-week-announcement-oct-2024-rcna171322\n",
            "46 https://www.nbcnews.com/select/deals-sales\n",
            "47 https://www.nbcnews.com/select/shopping/100-best-face-moisturizers-rcna151958\n",
            "48 https://www.nbcnews.com/select/shopping/weekly-sales-rcna123623\n",
            "49 https://www.nbcnews.com/select/deals-sales/weekly-sales\n",
            "50 https://www.nbcnews.com/select/shopping/sams-club-fall-membership-deal-rcna167230\n",
            "51 https://www.nbcnews.com/select/Paid\n",
            "52 https://www.nbcnews.com/news/us-news/baseless-rumors-haitian-immigrants-threaten-unravel-springfield-ohio-rcna170513\n",
            "53 https://www.nbcnews.com/news/world/are-killer-whale-attacks-rise-scientists-set-sail-find-rcna169295\n",
            "54 https://www.nbcnews.com/news/us-news/first-graders-survived-sandy-hook-will-vote-first-presidential-electio-rcna170471\n",
            "55 https://www.nbcnews.com/news/investigations/medical-debt-crisis-north-carolina-rcna161200\n",
            "56 https://www.nbcnews.com/business/business-news/federal-trial-michael-kors-says-harder-sell-handbags-tiktok-taylor-s-rcna171384\n",
            "57 https://www.nbcnews.com/business/autos/uaw-union-files-unfair-labor-charges-stellantis-accuses-automaker-viol-rcna171381\n",
            "58 https://www.nbcnews.com/business/business-news/boeing-freezes-hiring-sweeping-cost-cuts-grapples-factory-worker-strik-rcna171311\n",
            "59 https://www.nbcnews.com/business/shein-temu-prices-are-set-get-a-lot-higher-rcna171128\n",
            "60 https://www.nbcnews.com/news/asian-america/shogun-emmys-wins-awards-2024-rcna171040\n",
            "61 https://www.nbcnews.com/news/world/cologne-explosion-police-investigation-vanity-nightclub-germany-rcna171240\n",
            "62 https://www.nbcnews.com/news/world/china-frees-american-pastor-david-lin-rcna171236\n",
            "63 https://www.nbcnews.com/news/world/hong-kong-article-23-national-security-law-conviction-tshirt-sedition-rcna171247\n",
            "64 https://www.nbcnews.com/news/world/central-europe-braces-flooding-death-toll-rises-rcna171245\n",
            "65 https://www.nbcnews.com/news/world/3-hostages-likely-mistakenly-killed-idf-airstrike-rcna171197\n",
            "66 https://www.nbcnews.com/health/health-news/microplastics-brain-new-research-finds-plastics-olfactory-bulb-rcna171200\n",
            "67 https://www.nbcnews.com/health/health-news/cinnamon-powder-safe-high-lead-levels-found-many-samples-group-says-rcna170903\n",
            "68 https://www.nbcnews.com/health/health-news/cdc-says-no-clear-source-bird-flu-infection-missouri-patient-rcna170871\n",
            "69 https://www.nbcnews.com/health/health-news/florida-covid-shots-mrna-vaccines-older-adults-rcna170997\n",
            "70 https://www.nbcnews.com/science/science-news/supermoon-eclipse-will-visible-north-america-tuesday-rcna170484\n",
            "71 https://www.nbcnews.com/science/environment/650-foot-tsunami-greenland-rcna170322\n",
            "72 https://www.nbcnews.com/science/space/spacex-capsule-splashes-history-making-polaris-dawn-mission-rcna171063\n",
            "73 https://www.nbcnews.com/science/space/boeing-officials-quiet-return-starliner-spacecraft-rcna170601\n",
            "74 https://www.nbcnews.com/news/asian-america/china-initiative-asian-americans-house-gop-rcna171060\n",
            "75 https://www.nbcnews.com/news/asian-america/affirmative-action-enrollment-asian-americans-rcna170716\n",
            "76 https://www.nbcnews.com/news/us-news/haitians-ohio-find-solidarity-church-chaotic-week-false-pet-eating-cla-rcna171248\n",
            "77 https://www.nbcnews.com/news/obituaries/michaela-deprince-sierra-leonean-american-ballerina-boston-ballet-dies-rcna171135\n",
            "78 https://www.nbcnews.com/select/shopping/best-board-games-kids-ncna1266531\n",
            "79 https://www.nbcnews.com/select/home-kitchen\n",
            "80 https://www.nbcnews.com/select/shopping/amazon-prime-benefits-cost-ncna1269672\n",
            "81 https://www.nbcnews.com/select/prime-day\n",
            "82 https://www.nbcnews.com/select/shopping/best-printers-rcna171286\n",
            "83 https://www.nbcnews.com/select/tech/electronics\n",
            "84 https://www.nbcnews.com/select/wellness/sleep\n",
            "85 https://www.nbcnews.com/select/shopping/how-to-shop-for-a-mattress-online-rcna171284\n",
            "86 https://www.nbcnews.com/select/wellness/fitness\n",
            "87 https://www.nbcnews.com/select/shopping/best-affordable-indoor-exercise-bikes-ncna1245309\n",
            "88 https://www.nbcnews.com/pages/about-nbc-news-digital\n",
            "89 https://www.nbcnews.com/information/nbc-news-info/contact-us-n1232521\n",
            "90 https://www.nbcnews.com/info/closed-captioning\n",
            "91 https://www.nbcnews.com/politics/2024-election/live-blog/harris-trump-presidential-election-live-updates-rcna171168/rcrd55777?canonicalCard=true\n",
            "92 https://www.nbcnews.com/politics/2024-election/live-blog/harris-trump-presidential-election-live-updates-rcna171168/rcrd55751?canonicalCard=true\n",
            "93 https://www.nbcnews.com/politics/2024-election/live-blog/harris-trump-presidential-election-live-updates-rcna171168/rcrd55767?canonicalCard=true\n",
            "94 https://www.nbcnews.com/author/sahil-kapur-ncpn1123791\n",
            "95 https://www.nbcnews.com/politics/2024-election/presidential-debate-takeaways-trump-harris-rcna169060\n",
            "96 https://www.nbcnews.com/politics/2024-election/fact-check-presidential-debate-trump-harris-rcna169687\n",
            "97 https://www.nbcnews.com/author/katherine-doyle-ncpn1304357\n",
            "98 https://www.nbcnews.com/author/nicole-acevedo-ncpn384476\n",
            "99 https://www.nbcnews.com/news/latino/reggaeton-revolution-here-nicky-jam-saw-it-coming-n863371\n",
            "100 https://www.nbcnews.com/politics/immigration/trump-dreamers-daca-immigration-announcement-n798686\n"
          ]
        }
      ],
      "source": [
        "indexer = nbcnewsSpecificIndexer()\n",
        "for k, c in enumerate(\n",
        "                indexer\n",
        "                    .crawl_generator_for_index(\n",
        "                        \"https://www.nbcnews.com/\",\n",
        "                        3,\n",
        "                        \"docs_collection\",\n",
        "                        limit=100   # optional limit\n",
        "                    )):\n",
        "    print(k + 1, c.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO1CW_GtHbra"
      },
      "source": [
        "### Index statistics\n",
        "\n",
        "Load the index and print the statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iSQxbkczHbra",
        "outputId": "fcfe6de2-f011-4762-89e3-b8876642f78d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total index keys count 549\n",
            "\n",
            "Top stems by number of documents they apperared in:\n",
            "[('care', 18), ('skin', 17), ('after', 16), ('trump', 15), ('know', 7), ('harri', 7), ('nbc', 6), ('elect', 6), ('attempt', 6), ('what', 5), ('week', 5), ('say', 5), ('new', 5), ('make', 5), ('crypto', 5), ('best', 5), ('appar', 5), ('american', 5), ('about', 5), ('virtual', 4)]\n",
            "\n",
            "Top stems by overall frequency:\n",
            "[('care', 18), ('skin', 17), ('after', 16), ('trump', 15), ('know', 7), ('harri', 7), ('nbc', 6), ('elect', 6), ('attempt', 6), ('what', 5), ('week', 5), ('say', 5), ('s', 5), ('new', 5), ('make', 5), ('first', 5), ('crypto', 5), ('best', 5), ('appar', 5), ('american', 5)]\n"
          ]
        }
      ],
      "source": [
        "print('Total index keys count', len(indexer.index))\n",
        "\n",
        "print('\\nTop stems by number of documents they apperared in:')\n",
        "sorted_by_n_docs = sorted(indexer.index.items(), key=lambda kv: (len(kv[1]), kv[0]), reverse=True)\n",
        "print([(sorted_by_n_docs[i][0], len(sorted_by_n_docs[i][1])-1) for i in range(20)])\n",
        "\n",
        "print('\\nTop stems by overall frequency:')\n",
        "sorted_by_freq = sorted(indexer.index.items(), key=lambda kv: (kv[1][0], kv[0]), reverse=True)\n",
        "print([(sorted_by_freq[i][0], sorted_by_freq[i][1][0]) for i in range(20)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nik5EiNKHbra"
      },
      "source": [
        "## Answering a query (finally)\n",
        "\n",
        "Now, given that we already have built the inverted index, it's time to utilize it for answering user queries. In this class there are two methods you need to implement:\n",
        "- `boolean_retrieval`, the simplest form of document retrieval which returns a set of documents such that each one contains all query terms. Returns a set of document ids. Refer to *ch.1* of the book for details;\n",
        "- `okapi_scoring`, Okapi BM25 ranking function - assigns scores to documents in the collection that are relevant to the user query. Returns a dictionary of scores, `doc_id:score`. Read about it in [Wikipedia](https://en.wikipedia.org/wiki/Okapi_BM25#The_ranking_function) and implement accordingly.\n",
        "\n",
        "Both methods accept `query` parameter in a form of a dictionary, `term:frequency`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WAcmazWZHbra"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "class QueryProcessing:\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_query(raw_query):\n",
        "        prep = Preprocessor()\n",
        "        # pre-process query the same way as documents\n",
        "        query = prep.preprocess(raw_query)\n",
        "        # count frequency\n",
        "        return Counter(query)\n",
        "\n",
        "    @staticmethod\n",
        "    def boolean_retrieval(query, index):\n",
        "\n",
        "\n",
        "        # retrieve a set of documents containing all query terms\n",
        "        #TODO retrieve a set of documents containing all query terms\n",
        "        RetDocs = []\n",
        "        .\n",
        "        .\n",
        "        .\n",
        "        docs = set.intersection(*map(set,RetDocs))\n",
        "        return docs\n",
        "\n",
        "        return {0, 1, 3}\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def okapi_scoring(query, doc_lengths, index, k1=1.2, b=0.75):\n",
        "        #TODO retrieve relevant documents with scores\n",
        "\n",
        "        scores = {}\n",
        "        N = len(doc_lengths)\n",
        "        avgdl = sum(doc_lengths.values()) / float(len(doc_lengths))\n",
        "        for term in query.keys():\n",
        "            if term not in index:  # ignoring absent terms\n",
        "                continue\n",
        "            n_docs = ### TODO\n",
        "            idf = ### TODO\n",
        "            postings = index[term][1:]\n",
        "            for posting in postings:\n",
        "                doc_id = ### TODO\n",
        "                doc_tf = ### TODO\n",
        "                score = ### TODO\n",
        "                if doc_id not in scores:\n",
        "                    scores[doc_id] = score\n",
        "                else:  # accumulate scores\n",
        "                    scores[doc_id] += score\n",
        "        return scores\n",
        "        return {0: 0.32, 5: 1.17}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BimTi5vuHbra"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CLGC4LFkHbrb"
      },
      "outputs": [],
      "source": [
        "test_doc_lengths = {1: 20, 2: 15, 3: 10, 4:20, 5:30}\n",
        "test_index = {'x': [2, (1, 1), (2, 1)], 'y': [2, (1, 1), (3, 1)], 'z': [3, (2, 1), (4,2)]}\n",
        "\n",
        "\n",
        "test_query1 = QueryProcessing.prepare_query('x z')\n",
        "test_query2 = QueryProcessing.prepare_query('x y')\n",
        "\n",
        "\n",
        "assert QueryProcessing.boolean_retrieval(test_query1, test_index) == {2}\n",
        "assert QueryProcessing.boolean_retrieval(test_query2, test_index) == {1}\n",
        "okapi_res = QueryProcessing.okapi_scoring(test_query2, test_doc_lengths, test_index)\n",
        "assert all(k in okapi_res for k in (1, 2, 3))\n",
        "assert not any(k in okapi_res for k in (4, 5))\n",
        "assert okapi_res[1] > okapi_res[3] > okapi_res[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3S9ZiU2Hbrb"
      },
      "source": [
        "### And now query the real index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "g5F7qDBuHbrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e101e366-d3c3-4691-a5a2-b57c76ba621b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skin care\n",
            "\t https://www.nbcnews.com/select/shopping/target-circle-week-announcement-oct-2024-rcna171322\n",
            "\t https://www.nbcnews.com/select/deals-sales\n",
            "\t https://www.nbcnews.com/select/shopping/100-best-face-moisturizers-rcna151958\n",
            "\t https://www.nbcnews.com/select/shopping/weekly-sales-rcna123623\n",
            "\t https://www.nbcnews.com/select/deals-sales/weekly-sales\n",
            "\t https://www.nbcnews.com/select/shopping/sams-club-fall-membership-deal-rcna167230\n",
            "\t https://www.nbcnews.com/select/Paid\n",
            "\t https://www.nbcnews.com/select/shopping/best-board-games-kids-ncna1266531\n",
            "\t https://www.nbcnews.com/select/home-kitchen\n",
            "\t https://www.nbcnews.com/select/shopping/amazon-prime-benefits-cost-ncna1269672\n",
            "\t https://www.nbcnews.com/select/prime-day\n",
            "\t https://www.nbcnews.com/select/shopping/best-printers-rcna171286\n",
            "\t https://www.nbcnews.com/select/tech/electronics\n",
            "\t https://www.nbcnews.com/select/wellness/sleep\n",
            "\t https://www.nbcnews.com/select/shopping/how-to-shop-for-a-mattress-online-rcna171284\n",
            "\t https://www.nbcnews.com/select/wellness/fitness\n",
            "\t https://www.nbcnews.com/select/shopping/best-affordable-indoor-exercise-bikes-ncna1245309\n",
            "\t == Okapi Time: 0.00010 ==\n",
            "\t https://www.nbcnews.com/select/shopping/target-circle-week-announcement-oct-2024-rcna171322 1.098749063662141\n",
            "\t https://www.nbcnews.com/select/deals-sales 1.7003760098977487\n",
            "\t https://www.nbcnews.com/select/shopping/100-best-face-moisturizers-rcna151958 1.3037714359828643\n",
            "\t https://www.nbcnews.com/select/shopping/weekly-sales-rcna123623 1.1925123175658936\n",
            "\t https://www.nbcnews.com/select/deals-sales/weekly-sales 1.7003760098977487\n",
            "\t https://www.nbcnews.com/select/shopping/sams-club-fall-membership-deal-rcna167230 1.245662472857792\n",
            "\t https://www.nbcnews.com/select/Paid 1.810527770418009\n",
            "\t https://www.nbcnews.com/select/shopping/best-board-games-kids-ncna1266531 1.367567135019703\n",
            "\t https://www.nbcnews.com/select/home-kitchen 1.7003760098977487\n",
            "\t https://www.nbcnews.com/select/shopping/amazon-prime-benefits-cost-ncna1269672 1.245662472857792\n",
            "\t https://www.nbcnews.com/select/prime-day 1.6028587468563944\n",
            "\t https://www.nbcnews.com/select/shopping/best-printers-rcna171286 1.515920105732381\n",
            "\t https://www.nbcnews.com/select/tech/electronics 1.810527770418009\n",
            "\t https://www.nbcnews.com/select/wellness/sleep 1.810527770418009\n",
            "\t https://www.nbcnews.com/select/shopping/how-to-shop-for-a-mattress-online-rcna171284 1.367567135019703\n",
            "\t https://www.nbcnews.com/select/wellness/fitness 1.810527770418009\n",
            "\t https://www.nbcnews.com/select/shopping/best-affordable-indoor-exercise-bikes-ncna1245309 1.245662472857792\n",
            "\t https://www.nbcnews.com/politics/2024-election/donald-trump-misrepresents-repeal-affordable-care-act-obamacare-rcna171293 0.6374697462303839\n",
            "\n",
            "president elecetion\n",
            "\t https://www.nbcnews.com/news/latino/dreamers-blast-nicky-jam-endorsing-trump-sought-end-daca-president-rcna171307\n",
            "\t == Okapi Time: 0.00002 ==\n",
            "\t https://www.nbcnews.com/news/latino/dreamers-blast-nicky-jam-endorsing-trump-sought-end-daca-president-rcna171307 1.635957150071247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# queries = [\"russia missle\" , \"isreal palestine\", \"taylor swift\"]\n",
        "queries = ['skin care', 'president elecetion']\n",
        "for q in queries:\n",
        "    print(q)\n",
        "    qobj = QueryProcessing.prepare_query(q)\n",
        "    for res in QueryProcessing.boolean_retrieval(qobj, indexer.index):\n",
        "        print('\\t', indexer.doc_urls[res])\n",
        "\n",
        "    s = time.time()\n",
        "    okapi_res = QueryProcessing.okapi_scoring(qobj, indexer.doc_lengths, indexer.index)\n",
        "    e = time.time()\n",
        "    print(f\"\\t == Okapi Time: {e - s:.5f} ==\")\n",
        "    for res in okapi_res:\n",
        "        print('\\t', indexer.doc_urls[res], okapi_res[res])\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Gq2qy5z3KOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}