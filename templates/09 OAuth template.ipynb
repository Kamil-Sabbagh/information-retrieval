{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do you store in your Google Drive?\n",
    "\n",
    "Sometimes it can be quite troublesome to crawl web data - for example, when you can't just collect data from web-pages because the authentification to a website is required. Today's tutorial is about a dataset of special type - namely, Google Drive data. You will need to get access to the system using OAuth protocol and download and parse files of different types.\n",
    "\n",
    "Plan. \n",
    "1. Download [this little archive](https://drive.google.com/open?id=1Xji4A_dEAm_ycnO0Eq6vxj7ThcqZyJZR), **unzip** it and place the folder anywhere inside your Google Drive. You should get a subtree of 6 folders with files of different types: presentations, pdf-files, texts, and even code.\n",
    "2. Go to [Google Drive API](https://developers.google.com/drive/api/v3/quickstart/python) documentation, read [intro](https://developers.google.com/drive/api/v3/about-sdk) and learn how to [search for files](https://developers.google.com/drive/api/v3/reference/files/list) and [download](https://developers.google.com/drive/api/v3/manage-downloads) them.\n",
    "3. Learn how to open from python such files as [pptx](https://python-pptx.readthedocs.io/en/latest/user/quickstart.html), pdf, docx or even use generalized libraries like [textract](https://textract.readthedocs.io/en/stable/index.html).\n",
    "4. Build search index (preferably, inverted one) based on the documents you get and learn to retrieve file names (e.g. `at least this file.txt`) in response to a query. Validate your code on the following set of queries (there are documents for each of them!):\n",
    "```\n",
    "segmentation\n",
    "algorithm\n",
    "classifer\n",
    "printf\n",
    "predecessor\n",
    "Шеннон\n",
    "Huffman\n",
    "function\n",
    "constructor\n",
    "machine learning\n",
    "dataset\n",
    "Протасов\n",
    "Protasov\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Access GDrive ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of how you can oranize your code - it's fine if you change it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the list of all files that are contained (recursively) in the folder of interest. In my case, I called it `air_oauth_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gdrive_get_all_files_in_folder(folder_name):\n",
    "    #TODO retrieve all files from a given folder   \n",
    "    return []\n",
    "\n",
    "def gdrive_download_file(file, path_to_save): \n",
    "    #TODO download file and save it under the path\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "folder_of_interest = 'air_oauth_folder'\n",
    "files = gdrive_get_all_files_in_folder(folder_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download MS2 - Problems of multithread programming.pptx, 100%.\n",
      "Download DSA_15 Lion in the desert.pptx, 100%.\n",
      "Download DSA_09 - 2-3-4 and B-Trees.pdf, 100%.\n",
      "Download ai-junior.pdf, 100%.\n",
      "Download dsa.pdf, 100%.\n",
      "Download origin-06.mp3, 100%.\n",
      "Download L5-problems-2015.pdf, 100%.\n",
      "Download cs.pdf, 100%.\n",
      "Download 3cases.pdf, 100%.\n",
      "Download [DM]-Course Description.docx, 100%.\n",
      "Download Tutorial 9.pdf, 100%.\n",
      "Download FuncnNEW.pdf, 100%.\n",
      "Download Tutorial #8.pdf, 100%.\n",
      "Download students.txt, 100%.\n",
      "Download origin-05.mp3, 100%.\n",
      "Download rdtsc-vc.cpp, 100%.\n",
      "Download sort.js, 100%.\n",
      "Download skiplist.js, 100%.\n",
      "Download AY16-17 Academic Calendar .pdf, 100%.\n",
      "Download Assessment Criteria (May).pdf, 100%.\n",
      "Download rdtsc-gcc.c, 100%.\n",
      "Download retake-2016-08-18.docx, 100%.\n",
      "Download Program.cs, 100%.\n",
      "Download hockey.avi, 100%.\n",
      "Download nn.cpp, 100%.\n",
      "Download lockexamples.c, 100%.\n",
      "Download cyclomat.c, 100%.\n",
      "Download neuro.html, 100%.\n",
      "Download grant.txt, 100%.\n",
      "Download grant-translate.txt, 100%.\n",
      "Download bloomset.js, 100%.\n",
      "Download Small dataset face recognition.pptx, 100%.\n",
      "Download deep-features-scene (1).pdf, 100%.\n",
      "Download at least this file.txt, 100%.\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"test_files\"\n",
    "for item in files:\n",
    "    gdrive_download_file(item, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tests ##\n",
    "Please fill free to change function signatures and behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files: 34\n",
      "file here means id and name, e.g.:  ('15f8dFmQ0zzS7PIJM8JU2WDGGWnteZtAA', 'MS2 - Problems of multithread programming.pptx')\n",
      "Download MS2 - Problems of multithread programming.pptx, 100%.\n"
     ]
    }
   ],
   "source": [
    "assert len(files) == 34, 'Number of files is incorrect'\n",
    "print('n_files:', len(files))\n",
    "\n",
    "print(\"file here means id and name, e.g.: \", files[0])\n",
    "\n",
    "gdrive_download_file(files[0], '.')\n",
    "\n",
    "import os.path\n",
    "assert os.path.isfile(os.path.join('.', files[0][1])), \"File is not downloaded correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read files ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write here the code to extract text from the files you just downoaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for windows please refer to https://textract.readthedocs.io/en/latest/installation.html#don-t-see-your-operating-system-installation-instructions-here\n",
    "# https://www.xpdfreader.com/download.html\n",
    "# ALSO BE CAREFUL WITH SPACES IN NAMES. Better save without spaces!!!!!\n",
    "\n",
    "import textract \n",
    "\n",
    "def get_file_strings(path):\n",
    "    #TODO change this function to handle different data types properly - textract is not able to parse everything\n",
    "    # Take care of non-text data too\n",
    "    texts = str(textract.process(path)).replace('\\\\n', '\\n').replace('\\\\r', '').split('\\n')\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File format .avi is not supported\n",
      "File format .mp3 is not supported\n",
      "File format .mp3 is not supported\n"
     ]
    }
   ],
   "source": [
    "# creating dictionary of parsed files\n",
    "files_data = dict()\n",
    "for file in os.scandir(test_dir):    \n",
    "    strings = get_file_strings(file.path)\n",
    "    if strings:\n",
    "        files_data[file.name] = strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tests ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "assert len(files_data) == 31 \n",
    "print(len(files_data))\n",
    "\n",
    "assert \"Protasov\" in get_file_strings(os.path.join(test_dir, 'at least this file.txt')), \"TXT File parsed incorrectly\"\n",
    "assert \"A. Image classification\" in get_file_strings(os.path.join(test_dir, 'deep-features-scene (1).pdf')), \"PDF File parsed incorrectly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Index and search ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a search index based on files you just parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_inverted_index(files_data):\n",
    "    #TODO build search index from files    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "inverted_index = build_inverted_index(files_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find(query, index):\n",
    "    #TODO implement search procedure\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tests ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "queries = [\"segmentation\", \"algorithm\", \"printf\", \"predecessor\", \"Huffman\",\n",
    "           \"function\", \"constructor\", \"machine learning\", \"dataset\", \"Protasov\"]\n",
    "\n",
    "for query in queries:\n",
    "    r = find(query, inverted_index)\n",
    "#     print(\"Results for: \", query)\n",
    "#     print(\"\\t\", r)\n",
    "    assert len(r) > 0, \"Query should return at least 1 document\"\n",
    "    assert len(r) > 1, \"Query should return at least 2 documents\"\n",
    "    assert \"at least this file.txt\" in r, \"This file has all the queries. It should be in a result\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
